{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "AI20BTECH11021_KMeansClustering.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.8 64-bit ('base': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.8",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "bec9f652a4082306f869e119250ed899f786ad91c86aea518642b2537134d841"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## AI1104: Programming with AI\n",
        "\n",
        "Homework 1, Question 2: K Means Clustering\n",
        "\n",
        "Author: Tanmay Goyal, AI20BTECH11021"
      ],
      "metadata": {
        "id": "xn0wK4-zuMUo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "#importing required packages\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "_MPYhDhquHcS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "#taking user input for k and p\n",
        "\n",
        "print(\"Enter number of clusters k: \")\n",
        "k = int(input())\n",
        "print(\"Enter number of dimensions p: \")\n",
        "p = int(input())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter number of clusters k: \n"
          ]
        }
      ],
      "metadata": {
        "id": "_4nxMVrLuh58"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#to generate points, we would first generate random positions for means\n",
        "\n",
        "#there would be k means generated, with each mean having p dimensions\n",
        "\n",
        "mean_centroid = np.zeros((p,)) \n",
        "#all the data would eventually center around this point\n",
        "\n",
        "N_points = 2000\n",
        "\n",
        "#covariance matrix is assumed to be identity matrix, so that all dimensions are independent of one another\n",
        "cov = np.identity(p)\n",
        "\n",
        "Y = np.zeros((1, p)) \n",
        "#to store all data points, being initialised with a row of zeroes which will be deleted\n",
        "\n",
        "actual_means = np.zeros((1,p)) \n",
        "#to store the true means, being initialised with a row of zeroes which will be deleted\n",
        "\n",
        "\n",
        "for idx in range(k):\n",
        "    mean = [10*np.random.random() -5 for i in range(p)] #generating a random mean point between -5 and 5\n",
        "    print(\"Mean {} = {}\".format(idx , mean))\n",
        "    \n",
        "    actual_means = np.vstack((actual_means, mean))\n",
        "    \n",
        "    mean_centroid += mean\n",
        "    \n",
        "    y = np.random.multivariate_normal(mean , cov , N_points) \n",
        "    \n",
        "    # would generate points and matrix of the form [x1 , x2 , x3, x4]\n",
        "\n",
        "    Y = np.vstack((Y , y))\n",
        "\n",
        "mean_centroid /= k \n",
        "\n",
        "#deleting the initialised extra row\n",
        "Y = np.delete(Y , 0 , 0)\n",
        "actual_means = np.delete(actual_means , 0 , 0)\n",
        "\n",
        "\n",
        "print(\"Mean of centroids and data would lie at: \",mean_centroid)\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "qJbqNPSyp1Ao"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# to generate random initial centroids\n",
        "centroid_set = np.random.multivariate_normal(mean_centroid , cov , k)\n",
        "print(\"Initial guess of centroids is: \\n\", centroid_set)\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "Hxk31Qeov9c1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#introducing the loop \n",
        "\n",
        "count = 0 #iteration variable\n",
        "error = 100\n",
        "\n",
        "\n",
        "while error >0.0005 :\n",
        "    count += 1\n",
        "    centroid_updates = np.zeros((k , p))\n",
        "    number_cluster_points = np.zeros((k,)) #keeping track of number of points in each cluster\n",
        "    \n",
        "    #assigning each point to a cluster\n",
        "\n",
        "    for idx in range(N_points * k):\n",
        "        #setting distance between 0th centroid and datapoint as min\n",
        "        min = np.sum((centroid_set[0][:] - Y[idx][:])**2) #ignoring square root\n",
        "        \n",
        "        #keeping track of index of cluster\n",
        "        min_idx = 0\n",
        "\n",
        "        #finding rest of the distances in the dis variable, and finding the minimum \n",
        "        #distance to assign each point to a cluster\n",
        "        for cluster_idx in range(1, k):\n",
        "            dis = np.sum((centroid_set[cluster_idx][:] - Y[idx][:])**2) #ignoring square root\n",
        "            if dis < min:\n",
        "                min = dis\n",
        "                min_idx = cluster_idx\n",
        "\n",
        "        #min_idx keeps track of which point gets assigned to which cluster\n",
        "        #we will now update the centroid_update and number_cluster_points accordingly\n",
        "        #new centroid will be formed at center of each cluster \n",
        "        centroid_updates[min_idx][:] += Y[idx][:]\n",
        "        number_cluster_points[min_idx] += 1\n",
        "\n",
        "    #averaging the update distances\n",
        "    for idx in range(k):\n",
        "        \n",
        "        if (number_cluster_points[idx] ==0.0):\n",
        "            centroid_updates[idx][:] = mean_centroid.reshape((1,p))\n",
        "        else:\n",
        "            centroid_updates[idx][:] /= number_cluster_points[idx]\n",
        "\n",
        "    \n",
        "    error = np.sqrt(np.sum((centroid_updates - centroid_set)**2))\n",
        "    error /= k #averaging the error, else the larger the value of k, the more iterations\n",
        "    centroid_set = centroid_updates\n",
        "\n",
        "    print(\"Iteration {} : error = {}\".format(count, error))\n",
        "    print(\"Prediction of model: \\n\", centroid_set)\n",
        "    print(\"The number of points assigned to each cluster are \\n\" , number_cluster_points)\n",
        "    "
      ],
      "outputs": [],
      "metadata": {
        "id": "JUeAaoUJyaKb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#we will sort the predicted output and the actual centroids matrices by the first dimension for easier comparision\n",
        "\n",
        "centroid_set = centroid_set[centroid_set[:, 0].argsort()]\n",
        "\n",
        "actual_means = actual_means[actual_means[:,0].argsort()]\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "EJrSCaHH0w0G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#final output\n",
        "print(\"Prediction of model: \\n\", centroid_set)\n",
        "\n",
        "print(\"\\n Actual centroids : \\n\" , actual_means)\n",
        "\n",
        "print(\"\\n The number of points assigned to each cluster are \\n\" , number_cluster_points)\n",
        "\n",
        "print(\"\\n The predicted centroids end up very close to the actual centroids(compare element-wise).\\n\")\n",
        "\n",
        "print(\"The number of points assigned to each cluster is also very close to 2000. \\n\")\n",
        "\n",
        "print(\"The model works relatively well for smaller values of k and p. As the values of k and p increase\\\n",
        " the errors also start to creep up.\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "xHnv-uENN_bf"
      }
    }
  ]
}