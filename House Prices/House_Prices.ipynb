{
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "## AI1103: Programming with AI\n",
                "\n",
                "### Project: House price prediction dataset\n",
                "\n",
                "Source: https://www.kaggle.com/c/house-prices-advanced-regression-techniques\n",
                "\n",
                "Author: Tanmay Goyal, AI20BTECH11021"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### 1. Obtaining the prices manually"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "source": [
                "# importing the required modules\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# the following would be used to cross-check our results\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.decomposition import PCA\n",
                "from sklearn import linear_model\n",
                "from sklearn.linear_model import LinearRegression"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "source": [
                "# we would first read the train.csv file into train_df\n",
                "train_df = pd.read_csv(\"train.csv\")\n",
                "\n",
                "# printing the shape of train_df for our reference\n",
                "print(train_df.shape)\n",
                "\n",
                "# printing the first few rows of train_df for our reference\n",
                "train_df.head()"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "(1460, 81)\n"
                    ]
                },
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
                            "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
                            "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
                            "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
                            "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
                            "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
                            "\n",
                            "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
                            "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
                            "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
                            "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
                            "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
                            "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
                            "\n",
                            "  YrSold  SaleType  SaleCondition  SalePrice  \n",
                            "0   2008        WD         Normal     208500  \n",
                            "1   2007        WD         Normal     181500  \n",
                            "2   2008        WD         Normal     223500  \n",
                            "3   2006        WD        Abnorml     140000  \n",
                            "4   2008        WD         Normal     250000  \n",
                            "\n",
                            "[5 rows x 81 columns]"
                        ],
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>Id</th>\n",
                            "      <th>MSSubClass</th>\n",
                            "      <th>MSZoning</th>\n",
                            "      <th>LotFrontage</th>\n",
                            "      <th>LotArea</th>\n",
                            "      <th>Street</th>\n",
                            "      <th>Alley</th>\n",
                            "      <th>LotShape</th>\n",
                            "      <th>LandContour</th>\n",
                            "      <th>Utilities</th>\n",
                            "      <th>...</th>\n",
                            "      <th>PoolArea</th>\n",
                            "      <th>PoolQC</th>\n",
                            "      <th>Fence</th>\n",
                            "      <th>MiscFeature</th>\n",
                            "      <th>MiscVal</th>\n",
                            "      <th>MoSold</th>\n",
                            "      <th>YrSold</th>\n",
                            "      <th>SaleType</th>\n",
                            "      <th>SaleCondition</th>\n",
                            "      <th>SalePrice</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>1</td>\n",
                            "      <td>60</td>\n",
                            "      <td>RL</td>\n",
                            "      <td>65.0</td>\n",
                            "      <td>8450</td>\n",
                            "      <td>Pave</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>Reg</td>\n",
                            "      <td>Lvl</td>\n",
                            "      <td>AllPub</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>0</td>\n",
                            "      <td>2</td>\n",
                            "      <td>2008</td>\n",
                            "      <td>WD</td>\n",
                            "      <td>Normal</td>\n",
                            "      <td>208500</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>2</td>\n",
                            "      <td>20</td>\n",
                            "      <td>RL</td>\n",
                            "      <td>80.0</td>\n",
                            "      <td>9600</td>\n",
                            "      <td>Pave</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>Reg</td>\n",
                            "      <td>Lvl</td>\n",
                            "      <td>AllPub</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>0</td>\n",
                            "      <td>5</td>\n",
                            "      <td>2007</td>\n",
                            "      <td>WD</td>\n",
                            "      <td>Normal</td>\n",
                            "      <td>181500</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>3</td>\n",
                            "      <td>60</td>\n",
                            "      <td>RL</td>\n",
                            "      <td>68.0</td>\n",
                            "      <td>11250</td>\n",
                            "      <td>Pave</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>IR1</td>\n",
                            "      <td>Lvl</td>\n",
                            "      <td>AllPub</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>0</td>\n",
                            "      <td>9</td>\n",
                            "      <td>2008</td>\n",
                            "      <td>WD</td>\n",
                            "      <td>Normal</td>\n",
                            "      <td>223500</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>4</td>\n",
                            "      <td>70</td>\n",
                            "      <td>RL</td>\n",
                            "      <td>60.0</td>\n",
                            "      <td>9550</td>\n",
                            "      <td>Pave</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>IR1</td>\n",
                            "      <td>Lvl</td>\n",
                            "      <td>AllPub</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>0</td>\n",
                            "      <td>2</td>\n",
                            "      <td>2006</td>\n",
                            "      <td>WD</td>\n",
                            "      <td>Abnorml</td>\n",
                            "      <td>140000</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>5</td>\n",
                            "      <td>60</td>\n",
                            "      <td>RL</td>\n",
                            "      <td>84.0</td>\n",
                            "      <td>14260</td>\n",
                            "      <td>Pave</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>IR1</td>\n",
                            "      <td>Lvl</td>\n",
                            "      <td>AllPub</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>0</td>\n",
                            "      <td>12</td>\n",
                            "      <td>2008</td>\n",
                            "      <td>WD</td>\n",
                            "      <td>Normal</td>\n",
                            "      <td>250000</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>5 rows × 81 columns</p>\n",
                            "</div>"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 2
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "source": [
                "# reading the file test.csv into test_df\n",
                "test_df = pd.read_csv(\"test.csv\")\n",
                "\n",
                "# printing the shape of test_df for our reference\n",
                "print(test_df.shape)\n",
                "\n",
                "# printing the first few rows of test_df for our reference\n",
                "test_df.head()"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "(1459, 80)\n"
                    ]
                },
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "     Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
                            "0  1461          20       RH         80.0    11622   Pave   NaN      Reg   \n",
                            "1  1462          20       RL         81.0    14267   Pave   NaN      IR1   \n",
                            "2  1463          60       RL         74.0    13830   Pave   NaN      IR1   \n",
                            "3  1464          60       RL         78.0     9978   Pave   NaN      IR1   \n",
                            "4  1465         120       RL         43.0     5005   Pave   NaN      IR1   \n",
                            "\n",
                            "  LandContour Utilities  ... ScreenPorch PoolArea PoolQC  Fence MiscFeature  \\\n",
                            "0         Lvl    AllPub  ...         120        0    NaN  MnPrv         NaN   \n",
                            "1         Lvl    AllPub  ...           0        0    NaN    NaN        Gar2   \n",
                            "2         Lvl    AllPub  ...           0        0    NaN  MnPrv         NaN   \n",
                            "3         Lvl    AllPub  ...           0        0    NaN    NaN         NaN   \n",
                            "4         HLS    AllPub  ...         144        0    NaN    NaN         NaN   \n",
                            "\n",
                            "  MiscVal MoSold  YrSold  SaleType  SaleCondition  \n",
                            "0       0      6    2010        WD         Normal  \n",
                            "1   12500      6    2010        WD         Normal  \n",
                            "2       0      3    2010        WD         Normal  \n",
                            "3       0      6    2010        WD         Normal  \n",
                            "4       0      1    2010        WD         Normal  \n",
                            "\n",
                            "[5 rows x 80 columns]"
                        ],
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>Id</th>\n",
                            "      <th>MSSubClass</th>\n",
                            "      <th>MSZoning</th>\n",
                            "      <th>LotFrontage</th>\n",
                            "      <th>LotArea</th>\n",
                            "      <th>Street</th>\n",
                            "      <th>Alley</th>\n",
                            "      <th>LotShape</th>\n",
                            "      <th>LandContour</th>\n",
                            "      <th>Utilities</th>\n",
                            "      <th>...</th>\n",
                            "      <th>ScreenPorch</th>\n",
                            "      <th>PoolArea</th>\n",
                            "      <th>PoolQC</th>\n",
                            "      <th>Fence</th>\n",
                            "      <th>MiscFeature</th>\n",
                            "      <th>MiscVal</th>\n",
                            "      <th>MoSold</th>\n",
                            "      <th>YrSold</th>\n",
                            "      <th>SaleType</th>\n",
                            "      <th>SaleCondition</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>1461</td>\n",
                            "      <td>20</td>\n",
                            "      <td>RH</td>\n",
                            "      <td>80.0</td>\n",
                            "      <td>11622</td>\n",
                            "      <td>Pave</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>Reg</td>\n",
                            "      <td>Lvl</td>\n",
                            "      <td>AllPub</td>\n",
                            "      <td>...</td>\n",
                            "      <td>120</td>\n",
                            "      <td>0</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>MnPrv</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>0</td>\n",
                            "      <td>6</td>\n",
                            "      <td>2010</td>\n",
                            "      <td>WD</td>\n",
                            "      <td>Normal</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>1462</td>\n",
                            "      <td>20</td>\n",
                            "      <td>RL</td>\n",
                            "      <td>81.0</td>\n",
                            "      <td>14267</td>\n",
                            "      <td>Pave</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>IR1</td>\n",
                            "      <td>Lvl</td>\n",
                            "      <td>AllPub</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>Gar2</td>\n",
                            "      <td>12500</td>\n",
                            "      <td>6</td>\n",
                            "      <td>2010</td>\n",
                            "      <td>WD</td>\n",
                            "      <td>Normal</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>1463</td>\n",
                            "      <td>60</td>\n",
                            "      <td>RL</td>\n",
                            "      <td>74.0</td>\n",
                            "      <td>13830</td>\n",
                            "      <td>Pave</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>IR1</td>\n",
                            "      <td>Lvl</td>\n",
                            "      <td>AllPub</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>MnPrv</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>0</td>\n",
                            "      <td>3</td>\n",
                            "      <td>2010</td>\n",
                            "      <td>WD</td>\n",
                            "      <td>Normal</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>1464</td>\n",
                            "      <td>60</td>\n",
                            "      <td>RL</td>\n",
                            "      <td>78.0</td>\n",
                            "      <td>9978</td>\n",
                            "      <td>Pave</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>IR1</td>\n",
                            "      <td>Lvl</td>\n",
                            "      <td>AllPub</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>0</td>\n",
                            "      <td>6</td>\n",
                            "      <td>2010</td>\n",
                            "      <td>WD</td>\n",
                            "      <td>Normal</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>1465</td>\n",
                            "      <td>120</td>\n",
                            "      <td>RL</td>\n",
                            "      <td>43.0</td>\n",
                            "      <td>5005</td>\n",
                            "      <td>Pave</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>IR1</td>\n",
                            "      <td>HLS</td>\n",
                            "      <td>AllPub</td>\n",
                            "      <td>...</td>\n",
                            "      <td>144</td>\n",
                            "      <td>0</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1</td>\n",
                            "      <td>2010</td>\n",
                            "      <td>WD</td>\n",
                            "      <td>Normal</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>5 rows × 80 columns</p>\n",
                            "</div>"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 3
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "source": [
                "# A lot of the columns have Nans, so our first issue would be dealing with these\n",
                "\n",
                "# we first obtain a list of all columns having more than 50 Nans. Because of the larger number of Nans, we can safely\n",
                "# assume these columns would not contribute much towards the Price of the houses\n",
                "columns_with_Nans = train_df.isna().sum()>50\n",
                "\n",
                "# we now drop those columns from train_df\n",
                "for column in train_df.columns:\n",
                "    if columns_with_Nans[column] == True:\n",
                "        train_df.drop(column, axis=1 , inplace=True)\n",
                "\n",
                "# Those entries that still have Nans are now filled with the most common value from that specific column, since \n",
                "# the most common entry would be exerting larger influence \n",
                "train_df = train_df.apply(lambda x : x.fillna(x.value_counts().index[0]))\n",
                "\n",
                "# we check if any Nans remain in train_df\n",
                "print(train_df.isna().any().sum())\n",
                "\n",
                "# Finally, we drop the ID column, since it is only indexing our houses\n",
                "train_df.drop(['Id'] , axis = 1, inplace = True)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "0\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "source": [
                "# we would now remove those columns from test_df as well, which we assumed will not be \n",
                "# contributing significantly to the prices of the houses\n",
                "for column in test_df.columns:\n",
                "    if columns_with_Nans[column] == True:\n",
                "        test_df.drop(column, axis=1 , inplace=True)\n",
                "\n",
                "# again, we fill in the remaining Nans with the most common values from their columns\n",
                "test_df = test_df.apply(lambda x : x.fillna(x.value_counts().index[0]))\n",
                "\n",
                "# we check for any remaining Nans in test_df\n",
                "print(test_df.isna().any().sum())\n",
                "\n",
                "# we save the ID column from test_df for future references\n",
                "test_id = test_df['Id']\n",
                "\n",
                "# we drop the ID column from test_df\n",
                "test_df.drop(['Id'] , axis=1 , inplace = True)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "0\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "source": [
                "# the next issue we deal with is having categorical variables for regression.\n",
                "\n",
                "#we convert these variables into dummy variables for both train_df and test_df\n",
                "train_df = pd.get_dummies(train_df)\n",
                "test_df = pd.get_dummies(test_df)\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "source": [
                "# we then try to find the 20 most important features affecting the sale price of a house\n",
                "\n",
                "# we first find the correlation of every column with the SalePrice\n",
                "corr_list = np.array([train_df['SalePrice'].corr(train_df[column]) for column in train_df.columns])\n",
                "\n",
                "# we then sort these correlations, and make a list of the indices of all columns in order of the sorted list\n",
                "indices = np.argsort(corr_list)\n",
                "\n",
                "# we extract the 20 highest values\n",
                "# we exclude index -1 because that would be SalePrice column having correlation 1 with itself\n",
                "max_corr = indices[-21:-1]\n",
                "\n",
                "\n",
                "# we then extract the columns having highest correlation with SalePrice\n",
                "feature_columns = [train_df.columns[i] for i in max_corr]\n",
                "\n",
                "# we save the SalePrice column seperately for further use\n",
                "sale_price = train_df['SalePrice']\n",
                "\n",
                "# we remove the SalePrice column from train_df\n",
                "train_df.drop(['SalePrice'] , axis = 1 , inplace = True)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "source": [
                "# we now check if there are any extra columns in train_df\n",
                "print(set(train_df.columns) - set(test_df.columns))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "{'Exterior2nd_Other', 'Condition2_RRAe', 'HouseStyle_2.5Fin', 'Exterior1st_Stone', 'Condition2_RRNn', 'Heating_Floor', 'RoofMatl_Membran', 'Condition2_RRAn', 'Heating_OthW', 'RoofMatl_Roll', 'RoofMatl_ClyTile', 'Exterior1st_ImStucc', 'Electrical_Mix', 'RoofMatl_Metal', 'Utilities_NoSeWa'}\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "source": [
                "# the extra columns in train_df are now added to test_df, since we want both to have the same columns\n",
                "for idx , column in enumerate(train_df.columns):\n",
                "    if column not in test_df.columns:\n",
                "        test_df.insert(loc = idx , column = column , value = 0) \n",
                "        #since we know none of the rows hold that label of categorical variable\n",
                "    \n",
                "# we once again check if there remain any columns in train_df which are not found in test_df\n",
                "print(set(train_df.columns) - set(test_df.columns))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "set()\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "source": [
                "# finally, if there are any extra columns in test_df, which are not in train_df, they are dropped\n",
                "# since, our primary focus is train_df\n",
                "for idx , column in enumerate(test_df.columns):\n",
                "    if column not in train_df.columns:\n",
                "       test_df.drop(column, axis=1, inplace=True)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "source": [
                "#We make sure columns in test_df are in same order as that in train_df\n",
                "test_df = test_df[train_df.columns]\n",
                "\n",
                "#We check if the order is same\n",
                "print(train_df.columns == test_df.columns)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
                        "  True  True  True  True  True  True  True  True  True  True  True  True\n",
                        "  True  True  True  True  True  True  True  True  True  True  True  True\n",
                        "  True  True  True  True  True  True  True  True  True  True  True  True\n",
                        "  True  True  True  True  True  True  True  True  True  True  True  True\n",
                        "  True  True  True  True  True  True  True  True  True  True  True  True\n",
                        "  True  True  True  True  True  True  True  True  True  True  True  True\n",
                        "  True  True  True  True  True  True  True  True  True  True  True  True\n",
                        "  True  True  True  True  True  True  True  True  True  True  True  True\n",
                        "  True  True  True  True  True  True  True  True  True  True  True  True\n",
                        "  True  True  True  True  True  True  True  True  True  True  True  True\n",
                        "  True  True  True  True  True  True  True  True  True  True  True  True\n",
                        "  True  True  True  True  True  True  True  True  True  True  True  True\n",
                        "  True  True  True  True  True  True  True  True  True  True  True  True\n",
                        "  True  True  True  True  True  True  True  True  True  True  True  True\n",
                        "  True  True  True  True  True  True  True  True  True  True  True  True\n",
                        "  True  True  True  True  True  True  True  True  True  True  True  True\n",
                        "  True  True  True  True  True  True  True  True  True  True  True  True\n",
                        "  True  True  True  True  True  True  True  True  True  True  True  True\n",
                        "  True  True  True  True  True  True  True  True  True  True  True  True\n",
                        "  True  True  True  True  True  True  True  True  True]\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "source": [
                "# we convert our sale_price to np array for calculations\n",
                "y_train = np.array(sale_price)\n",
                "\n",
                "# we extract the 20 columns having maximum impact on saleprice as our X_train\n",
                "X_train = np.array(train_df[feature_columns])\n",
                "\n",
                "# we extract the same 20 columns having maximum impact on saleprice as our X_test\n",
                "X_test = np.array(test_df[feature_columns])\n",
                "\n",
                "# we add a column of ones to accomodate the bias term for both X_train and X_test\n",
                "X_train = np.hstack((np.ones((X_train.shape[0] , 1)), X_train))\n",
                "X_test = np.hstack((np.ones((X_test.shape[0] , 1)), X_test))"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "For a linear regression, we know the optimal set of weights is given by:\n",
                "\n",
                "$\\beta ^ * = (X^T  X) ^{-1}  X^T  y$\n",
                "\n",
                "where $(X^T  X) ^{-1}$ is called as the pseudo-inverse of $X$."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "source": [
                "#calculating the psuedo- inverse of X\n",
                "pseudo_inv = np.linalg.inv(np.matmul(X_train.T , X_train))\n",
                "\n",
                "#calculating the optimal set of weights using the equation mentioned above\n",
                "beta = pseudo_inv @ X_train.T @ y_train\n",
                "\n",
                "#checking if number of columns of beta match number of columns in X\n",
                "print(beta.shape[0] , X_train.shape[1])\n"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "21 21\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "source": [
                "# finally, we save our predictions under result_m\n",
                "result_m = X_test @ beta\n",
                "result_m"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "array([102787.06162586, 139660.42990578, 179900.90111694, ...,\n",
                            "       154926.48445969, 113714.73141107, 222990.68043667])"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 14
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### Obtaining the solution using in- built libraries"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "source": [
                "# we first extract the train_df and test_df values \n",
                "x_train = train_df.values\n",
                "x_test = test_df.values"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "source": [
                "# we transform all data into zero mean and unit variance\n",
                "x_train = StandardScaler().fit_transform(x_train)\n",
                "x_test = StandardScaler().fit_transform(x_test)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "source": [
                "# since we had used 20 components for obtaining the solution manually, \n",
                "# we would decompose the data into 20 components as well\n",
                "pca = PCA(n_components = 20)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "source": [
                "# we fit the training data to this pca model\n",
                "pca.fit(x_train)\n",
                "\n",
                "# we now apply the transform to both testing and training data\n",
                "x_train = pca.transform(x_train)\n",
                "x_test = pca.transform(x_test)\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "source": [
                "# setting up the Linear Regression model\n",
                "model=LinearRegression()\n",
                "\n",
                "# we fit the training data, as well as the target variable SalePrice to this model\n",
                "model.fit(x_train,sale_price)"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "LinearRegression()"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 19
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "source": [
                "# we now predict the outputs for the testing data and store it in result_scikit\n",
                "result_scikit = model.predict(x_test)\n",
                "result_scikit"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "array([104745.69147659, 178405.89753071, 186087.28250348, ...,\n",
                            "       165406.92050327, 114453.83201366, 229369.80124488])"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 20
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "source": [
                "# we compile both the results to compare\n",
                "\n",
                "final_result = pd.DataFrame({'Id' : test_id , 'Results computed Manually' : result_m , 'Results using Scikit Learn' : result_scikit})\n",
                "final_result"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "        Id  Results computed Manually  Results using Scikit Learn\n",
                            "0     1461              102787.061626               104745.691477\n",
                            "1     1462              139660.429906               178405.897531\n",
                            "2     1463              179900.901117               186087.282503\n",
                            "3     1464              194346.068237               212029.115088\n",
                            "4     1465              191294.322196               188832.328053\n",
                            "...    ...                        ...                         ...\n",
                            "1454  2915               81511.108838                89444.483876\n",
                            "1455  2916               93768.489789                99935.326326\n",
                            "1456  2917              154926.484460               165406.920503\n",
                            "1457  2918              113714.731411               114453.832014\n",
                            "1458  2919              222990.680437               229369.801245\n",
                            "\n",
                            "[1459 rows x 3 columns]"
                        ],
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>Id</th>\n",
                            "      <th>Results computed Manually</th>\n",
                            "      <th>Results using Scikit Learn</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>1461</td>\n",
                            "      <td>102787.061626</td>\n",
                            "      <td>104745.691477</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>1462</td>\n",
                            "      <td>139660.429906</td>\n",
                            "      <td>178405.897531</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>1463</td>\n",
                            "      <td>179900.901117</td>\n",
                            "      <td>186087.282503</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>1464</td>\n",
                            "      <td>194346.068237</td>\n",
                            "      <td>212029.115088</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>1465</td>\n",
                            "      <td>191294.322196</td>\n",
                            "      <td>188832.328053</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>...</th>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1454</th>\n",
                            "      <td>2915</td>\n",
                            "      <td>81511.108838</td>\n",
                            "      <td>89444.483876</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1455</th>\n",
                            "      <td>2916</td>\n",
                            "      <td>93768.489789</td>\n",
                            "      <td>99935.326326</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1456</th>\n",
                            "      <td>2917</td>\n",
                            "      <td>154926.484460</td>\n",
                            "      <td>165406.920503</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1457</th>\n",
                            "      <td>2918</td>\n",
                            "      <td>113714.731411</td>\n",
                            "      <td>114453.832014</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1458</th>\n",
                            "      <td>2919</td>\n",
                            "      <td>222990.680437</td>\n",
                            "      <td>229369.801245</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>1459 rows × 3 columns</p>\n",
                            "</div>"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 21
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "source": [
                "# We also calculate the RMSE error\n",
                "error = np.sum((np.array(result_scikit)-np.array(result_m))**2)\n",
                "error/= final_result.shape[0]\n",
                "error = error ** 0.5\n",
                "print(\"RMSE error: {:.2f}\".format(error))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "RMSE error: 18612.39\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "### RMSE vs Number of components:\n",
                "\n",
                "As the number of components we consider increases, the accuracy of the model increases, and the RMSE decreases "
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "source": [
                "# copying the relevant snippets of code from above    \n",
                "components = [i for i in range (1,51)]\n",
                "errors = []\n",
                "\n",
                "for n in range(1,51):    \n",
                "    error = 0\n",
                "    train_df = pd.read_csv(\"train.csv\")\n",
                "    test_df = pd.read_csv(\"test.csv\")\n",
                "    \n",
                "    columns_with_Nans = train_df.isna().sum()>50\n",
                "\n",
                "    for column in train_df.columns:\n",
                "        if columns_with_Nans[column] == True:\n",
                "            train_df.drop(column, axis=1 , inplace=True)\n",
                "\n",
                "    train_df = train_df.apply(lambda x : x.fillna(x.value_counts().index[0]))\n",
                "    train_df.drop(['Id'] , axis = 1, inplace = True)\n",
                "\n",
                "    for column in test_df.columns:\n",
                "        if columns_with_Nans[column] == True:\n",
                "            test_df.drop(column, axis=1 , inplace=True)\n",
                "\n",
                "    test_df = test_df.apply(lambda x : x.fillna(x.value_counts().index[0]))\n",
                "    test_df.drop(['Id'] , axis=1 , inplace = True)\n",
                "    \n",
                "    train_df = pd.get_dummies(train_df)\n",
                "    test_df = pd.get_dummies(test_df)\n",
                "\n",
                "    corr_list = np.array([train_df['SalePrice'].corr(train_df[column]) for column in train_df.columns])\n",
                "    indices = np.argsort(corr_list)\n",
                "    max_corr = indices[(-1-n):-1]\n",
                "    feature_columns = [train_df.columns[i] for i in max_corr]\n",
                "\n",
                "    sale_price = train_df['SalePrice']\n",
                "    train_df.drop(['SalePrice'] , axis = 1 , inplace = True)\n",
                "\n",
                "    for idx , column in enumerate(train_df.columns):\n",
                "        if column not in test_df.columns:\n",
                "            test_df.insert(loc = idx , column = column , value = 0) \n",
                "        \n",
                "   \n",
                "    for idx , column in enumerate(test_df.columns):\n",
                "        if column not in train_df.columns:\n",
                "            test_df.drop(column, axis=1, inplace=True)\n",
                "    \n",
                "    test_df = test_df[train_df.columns]\n",
                "\n",
                "    y_train = np.array(sale_price)\n",
                "    X_train = np.array(train_df[feature_columns])\n",
                "    X_test = np.array(test_df[feature_columns])\n",
                "    X_train = np.hstack((np.ones((X_train.shape[0] , 1)), X_train))\n",
                "    X_test = np.hstack((np.ones((X_test.shape[0] , 1)), X_test))\n",
                "\n",
                "    pseudo_inv = np.linalg.inv(np.matmul(X_train.T , X_train))\n",
                "    beta = pseudo_inv @ X_train.T @ y_train\n",
                "\n",
                "    result_m = X_test @ beta\n",
                "    \n",
                "\n",
                "    x_train = train_df.values\n",
                "    x_test = test_df.values\n",
                "    x_train = StandardScaler().fit_transform(x_train)\n",
                "    x_test = StandardScaler().fit_transform(x_test)\n",
                "    \n",
                "    pca = PCA(n_components = n)\n",
                "    pca.fit(x_train)\n",
                "\n",
                "    x_train = pca.transform(x_train)\n",
                "    x_test = pca.transform(x_test)\n",
                "\n",
                "    model=LinearRegression()\n",
                "    model.fit(x_train,sale_price)\n",
                "    result_scikit = model.predict(x_test)\n",
                "   \n",
                "\n",
                "    error = np.sum((np.array(result_scikit)-np.array(result_m))**2)\n",
                "    error/= final_result.shape[0]\n",
                "    error = error ** 0.5\n",
                "    errors.append(error)\n",
                "\n",
                "plt.plot(components , errors , 'r' , label = \"RSME\")\n",
                "plt.grid(True)\n",
                "plt.legend()\n",
                "plt.xlabel(\"Number of Principal Components\")\n",
                "plt.ylabel(\"RSME\")\n",
                "plt.title(\"RSME vs Number of Principal Components\")\n",
                "plt.show()    "
            ],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.8.8",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.8.8 64-bit ('base': conda)"
        },
        "interpreter": {
            "hash": "bec9f652a4082306f869e119250ed899f786ad91c86aea518642b2537134d841"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}